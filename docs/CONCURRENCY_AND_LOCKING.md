# Concurrency & Locking Architecture (Phase 0.14)

> **Note**: In this document and the codebase, the term **"Agent"** refers to any **Autonomous Component** (Service, AI, Tool, or Human Interface) managed by the Runtime.

This document describes the concurrency control mechanisms implemented in MeshForge Runtime to prevent double-writes and manage coordination between agents without compromising the core's purity or determinism.

## 1. Core: Optimistic Concurrency (Anti-Double Write)

MeshForge employs an **Event-Sourced Optimistic Concurrency** model. This ensures that an agent only modifies state if it is acting on the version of the state it expects.

### Principles
- **No Blocking Locks**: The Runtime Core does not use mutexes or blocking waits for business logic.
- **Determinism**: Replaying the same command stream always results in the same outcome (Success or Conflict).
- **Persistence**: Conflict decisions are persisted as events to ensure the history explains *why* a command failed during replay.
- **Version Authority**: The version of an entity is derived exclusively from the EventStore and is immutable outside of event replay.
- **Entity-Level Granularity**: Concurrency checks are performed per-entity. Updates to Entity A do not conflict with updates to Entity B.

### Mechanism
1.  **Command**: A command may optionally include an `expected_version` field in the `EventEnvelope` and MUST specify `entity_id`. If `expected_version` is omitted, the command is processed without concurrency guarantees.
2.  **Runtime Check**:
    - Before invoking the Agent Adapter, the `RuntimeEngine` retrieves the current state version for the target `entity_id`.
    - If `envelope.expected_version != entity_version`:
        - The command is **rejected**.
        - A `ConflictEvent` (`evt.<agent_name>.conflict`) is generated.
        - The conflict event is **persisted** to the Event Store and **published** to the bus.
        - The Agent Adapter's `receive()` method is **skipped**.
3.  **Success**: If versions match (or no version is provided), processing proceeds normally.

### Conflict Event Schema
```json
{
  "type": "evt.<agent_name>.conflict",
  "payload": {
    "entity_id": "uuid",
    "expected_version": 10,
    "current_version": 11,
    "reason": "Version mismatch for entity <uuid>: expected 10, got 11"
  },
  "idempotency_key": "<original_command_key>"
}
```

### Usage
Clients (Agents/UI) should:
1.  Read the current state of the entity (specifically its `entity_version` from `entity_versions` map or entity payload).
2.  Send a command with `expected_version` set to the read `entity_version` and `entity_id` set.
3.  Handle `evt.<agent_name>.conflict` responses by refreshing state and retrying (if appropriate).

## 2. LockManager (Optional Module)

For long-running tasks, external resource coordination, or "critical sections" spanning multiple commands, MeshForge provides an optional **LockManager** system agent.

### Role
- **Cooperative Locking**: Provides advisory locks via Lease mechanism.
- **System Agent**: Runs as a distinct agent (`sys_lock_manager`) within the runtime.
- **Event-Driven**: All lock operations are commands and events.

### API (Commands)

| Command | Payload | Description |
|---|---|---|
| `cmd.lock.acquire` | `{ "resource_id": "str", "owner_id": "str", "ttl_ms": int }` | Request a lock. |
| `cmd.lock.release` | `{ "resource_id": "str", "owner_id": "str" }` | Release a lock. |
| `cmd.lock.refresh` | `{ "resource_id": "str", "owner_id": "str", "ttl_ms": int }` | Extend a lease. |

### Events

| Event | Payload | Description |
|---|---|---|
| `evt.lock.acquired` | `{ "resource_id", "owner_id", "expires_at" }` | Lock successfully granted. |
| `evt.lock.denied` | `{ "resource_id", "requested_by", "current_owner", "reason" }` | Lock refused (already held). |
| `evt.lock.released` | `{ "resource_id", "owner_id" }` | Lock released. |
| `evt.lock.expired` | `{ "resource_id" }` | TTL expired (generated by system tick). |

### Configuration
Enabled via Factory Profile:
```yaml
component_toggles:
  lock_manager: true
```

## 3. Integration & Testing

### NATS Subjects
- Commands to LockManager: `cmd.{tenant}.{workspace}.sys_lock_manager.>`
- Events from LockManager: `evt.{tenant}.{workspace}.lock.>`

### Validation
The implementation is validated via `smoke_test_concurrency.py` in the integration workspace, ensuring:
1.  **Optimistic Failure**: Updates with stale versions are rejected with conflicts.
2.  **Optimistic Success**: Updates with correct versions are applied.
3.  **Locking**: Exclusive access behavior (Acquire -> Deny Different Owner).
